{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 57 - HOW TO GENERATE FEATURES FOR Machine Learning \n",
    "\n",
    "# https://github.com/bnsreenu/python_for_microscopists/blob/master/057-ML_06_02_what%20are%20features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from scipy import ndimage as nd\n",
    "from skimage.filters import sobel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./camera/2006251215008901.jpg') #RGB image -> convert to single color\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img, (256, 256), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features vectors with Pandas df\n",
    "# Convert into one single list or array \n",
    "# Unwrap my image into a 1D array\n",
    "\n",
    "img2 = img.reshape(-1)\n",
    "df = pd.DataFrame()\n",
    "df['Original Pixel Values'] = img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Entropy filter (lack of order), measure of disorder\n",
    "\n",
    "entropy_img = entropy(img, disk(1))\n",
    "entropy1 = entropy_img.reshape(-1)\n",
    "df['Entropy'] = entropy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Gaussian filter\n",
    "\n",
    "gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "gaussian1 = gaussian_img.reshape(-1)\n",
    "df['Gaussian'] = gaussian1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sobel filter \n",
    "\n",
    "sobel_img = sobel(img)\n",
    "sobel1 = sobel_img.reshape(-1)\n",
    "df['Sobel'] = sobel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check other tutorials for Gabor filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Pixel Values</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Gaussian</th>\n",
       "      <th>Sobel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>138</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Pixel Values   Entropy  Gaussian  Sobel\n",
       "0                    189  1.584963       149    0.0\n",
       "1                    195  2.000000       145    0.0\n",
       "2                    161  2.000000       138    0.0\n",
       "3                    153  2.000000       129    0.0\n",
       "4                    111  2.000000       121    0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise Each: \n",
    "\n",
    "cv2.imshow('Entropy', entropy_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('Gaussian', gaussian_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('Sobel', sobel_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51 - IMAGE SEGMENTATION USING K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check openCV K-means Clustering documentation\n",
    "\n",
    "im = cv2.imread('./camera/2006251815008927.jpg')\n",
    "im = cv2.resize(im, (200,200),3)\n",
    "\n",
    "im2 = im.reshape((-1,3))\n",
    "im2 = np.float32(im2)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "\n",
    "#Clusters\n",
    "k = 8\n",
    "\n",
    "#times algorithm is repeated\n",
    "attempts = 20 \n",
    "\n",
    "ret,label,center=cv2.kmeans(im2,k,None,criteria,attempts,cv2.KMEANS_PP_CENTERS) #can use PP_centers or random_centers for how center is assigned \n",
    "\n",
    "# Now convert back into uint8 (unsigned integers), and make original image\n",
    "center = np.uint8(center)\n",
    "# Flatten labels\n",
    "res = center[label.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape them\n",
    "res2 = res.reshape((im.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('segmented.jpg', res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('res2',res2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 52 - IMAGE SEGMENTATION USING GAUSSIAN MIXTURE MODEL (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 approaches into different umbrellas:\n",
    "\n",
    "# Unsupervised Learning\n",
    "# Figure out where features are\n",
    "\n",
    "# Supervised Learning \n",
    "# Supply a labeled image where you paint the pixels and label them\n",
    "# Save model and use to train future models\n",
    "\n",
    "# GMM is another example of Clustering technique falling into image/data processing\n",
    "#Clusters overlap then GMM is more suitable because K-means has hard assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./camera/2006251815008927.jpg')\n",
    "img = cv2.resize(im, (200,200),3)\n",
    "img2 = img.reshape((-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define instance, model\n",
    "# Step 2: Fit it to data you have\n",
    "# Step 3: Predict using data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoke my GMM\n",
    "gmm_model = GMM(n_components=2, covariance_type='tied').fit(img2)\n",
    "#type is also spherical or diagonal not only tied, depends on type of data. Check documentation\n",
    "\n",
    "#Generate labels\n",
    "gmm_labels = gmm_model.predict(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_shape = img.shape\n",
    "segmented = gmm_labels.reshape(original_shape[0], original_shape[1])\n",
    "cv2.imwrite('segmented_im.jpg', segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 66 - IMAGE SEGMENTATION - TRADITIONAL ML\n",
    "\n",
    "# Code adapted from: https://github.com/bnsreenu/python_for_microscopists/blob/master/062-066-ML_06_04_TRAIN_ML_segmentation_All_filters_RForest.py\n",
    "# STEP 1: FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to train SUPPORT VECTOR MACHINE for image segmentation\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "img = cv2.imread('./camera/2006251300008904.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add features to dataframe needed for our ML algorithm\n",
    "#Pixel value tells a lot about what each region is\n",
    "\n",
    "#Feature #1 is our original pixel values to the data frame added\n",
    "img2 = img.reshape(-1)\n",
    "df = pd.DataFrame()\n",
    "df['Original Image'] = img2\n",
    "#print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add other features \n",
    "\n",
    "# First set: Gabor Features (like gaussian or any kind of edge\n",
    "# detection features). Create a gabor filter bank to generate reponses onto the original image. \n",
    "\n",
    "\n",
    "# Generate Gabor features: this combination gives 32 different filters\n",
    "num = 1\n",
    "kernels = []\n",
    "for theta in range(2):\n",
    "    theta = theta / 4. * np.pi\n",
    "    for sigma in (1,3):\n",
    "        for lamda in np.arange(0, np.pi, np.pi / 4):\n",
    "            for gamma in (0.05,0.5):\n",
    "                \n",
    "                gabor_label = 'Gabor' + str(num)\n",
    "                ksize = 5 #or 9\n",
    "                kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
    "                kernels.append(kernel)\n",
    "                #Now fikter the image and add values to a new column\n",
    "                fimg = cv2.filter2D(img2, cv2.CV_8UC3, kernel)\n",
    "                filtered_img = fimg.reshape(-1)\n",
    "                df[gabor_label] = filtered_img #labels columns as Gabor1, Gabor2 \n",
    "                print(gabor_label, ': theta=', theta, ':sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "                num += 1 #Increment for gabor column label\n",
    "\n",
    "print(df.head())                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other feature extractors: \n",
    "\n",
    "# Canny Edge: Edge detection \n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "edges1 = edges.reshape(-1)\n",
    "df['Canny Edge'] = edges1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "\n",
    "#ROBERTS EDGE\n",
    "edge_roberts = roberts(img)\n",
    "edge_roberts1 = edge_roberts.reshape(-1)\n",
    "df['Roberts'] = edge_roberts1\n",
    "\n",
    "#SOBEL\n",
    "edge_sobel = sobel(img)\n",
    "edge_sobel1 = edge_sobel.reshape(-1)\n",
    "df['Sobel'] = edge_sobel1\n",
    "\n",
    "#SCHARR\n",
    "edge_scharr = scharr(img)\n",
    "edge_scharr1 = edge_scharr.reshape(-1)\n",
    "df['Scharr'] = edge_scharr1\n",
    "\n",
    "#PREWITT\n",
    "edge_prewitt = prewitt(img)\n",
    "edge_prewitt1 = edge_prewitt.reshape(-1)\n",
    "df['Prewitt'] = edge_prewitt1\n",
    "\n",
    "#GAUSSIAN with sigma=3\n",
    "from scipy import ndimage as nd\n",
    "gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "gaussian_img1 = gaussian_img.reshape(-1)\n",
    "df['Gaussian s3'] = gaussian_img1\n",
    "\n",
    "#GAUSSIAN with sigma=7\n",
    "gaussian_img2 = nd.gaussian_filter(img, sigma=7)\n",
    "gaussian_img3 = gaussian_img2.reshape(-1)\n",
    "df['Gaussian s7'] = gaussian_img3\n",
    "\n",
    "#MEDIAN with sigma=3\n",
    "median_img = nd.median_filter(img, size=3)\n",
    "median_img1 = median_img.reshape(-1)\n",
    "df['Median s3'] = median_img1\n",
    "\n",
    "#VARIANCE with size=3\n",
    "# slow part, we may not need that\n",
    "# variance_img = nd.generic_filter(img, np.var, size=3)\n",
    "# variance_img1 = variance_img.reshape(-1)\n",
    "# df['Variance s3'] = variance_img1  #Add column to original dataframe\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another column that corresponds to the feature image\n",
    "# We need to tell what ground truth is (training)\n",
    "labeled_img = cv2.imread('./2105011200000000.png')\n",
    "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
    "labeled_img1 = labeled_img.reshape(-1)\n",
    "df['Labels'] = labeled_img1\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: TRAINING A MODEL (USING RANDOM FOREST CLASSIFIER RFC)\n",
    "\n",
    "# Define dependent variable Y \n",
    "Y = df['Labels'].values\n",
    "\n",
    "# Define independent variable X\n",
    "X = df.drop(labels = ['Labels'], axis=1) #keep everything except Labels column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and train\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state=20)\n",
    "\n",
    "#Import ML algorithm and train model\n",
    "\n",
    "# here we use random forest as our classifier:\n",
    "# RandomForestRegressor works too but predicts a number value of data \n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#model = RandomForestClassifier(n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# USE SVM Method ##############\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(max_iter=100) #try 1000 too (accuracy increases)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = model.predict(X_train)\n",
    "#use predict.proba for probability\n",
    "prediction_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics for accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "#compare\n",
    "#Y_test is our True \n",
    "print('Accuracy =', metrics.accuracy_score(Y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: SAVING TRAINED MODEL\n",
    "#Use this model to segment other images\n",
    "\n",
    "import pickle\n",
    "filename = 'ourfirst_model'\n",
    "pickle.dump(model, open(filename, 'wb')) # wb= write in binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the model to train: import it \n",
    "load_model = pickle.load(open(filename, 'rb')) #rb = read binary mode\n",
    "result = load_model.predict(X) #Predict all pixels in X\n",
    "\n",
    "segmented = result.reshape((img.shape))\n",
    "\n",
    "#Visualise\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(segmented, cmap='jet')\n",
    "plt.imsave('segmented_img.jpg', segmented, cmap='jet')\n",
    "\n",
    "#If I'm happy with this segmentation as a working image, let's apply\n",
    "# that to all the images and move to production mode. \n",
    "\n",
    "#Place all images in folder train_images in the Segmented folder \n",
    "#To do so, create a copy of this notebook file up until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: SEGMENTING MULTIPLE IMAGES USING A SAVED MODEL\n",
    "\n",
    "#Feature extraction \n",
    "# Code to train random forest for image segmentation\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "#########\n",
    "# STEP 5 - Adding code here \n",
    "\n",
    "#Function:\n",
    "def feature_extraction(img): #img that we'll supply later\n",
    "    df = pd.DataFrame() #Create empty dataframe\n",
    "    \n",
    "    #Add original pixel values to df as feature #1\n",
    "    img2 = img.reshape(-1)\n",
    "    df['Original Image'] = img2\n",
    "    #print(df.head)\n",
    "\n",
    "#Add other features \n",
    "# First set: Gabor Features\n",
    "# Generate Gabor features\n",
    "    num = 1\n",
    "    kernels = []\n",
    "    for theta in range(2):\n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1,3):\n",
    "            for lamda in np.arange(0, np.pi, np.pi / 4):\n",
    "                for gamma in (0.05,0.5):\n",
    "                \n",
    "                    gabor_label = 'Gabor' + str(num)\n",
    "                    ksize = 5 #or 9\n",
    "                    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
    "                    kernels.append(kernel)\n",
    "                #Now filter the image and add values to a new column\n",
    "                    fimg = cv2.filter2D(img2, cv2.CV_8UC3, kernel)\n",
    "                    filtered_img = fimg.reshape(-1)\n",
    "                    df[gabor_label] = filtered_img #labels columns as Gabor1, Gabor2 \n",
    "                    print(gabor_label, ': theta=', theta, ':sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "                    num += 1 #Increment for gabor column label\n",
    "\n",
    "#print(df.head())  \n",
    "# Add other feature extractors: \n",
    "    # Canny Edge: Edge detection \n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    edges1 = edges.reshape(-1)\n",
    "    df['Canny Edge'] = edges1\n",
    "\n",
    "    from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "\n",
    "    #ROBERTS EDGE\n",
    "    edge_roberts = roberts(img)\n",
    "    edge_roberts1 = edge_roberts.reshape(-1)\n",
    "    df['Roberts'] = edge_roberts1\n",
    "\n",
    "    #SOBEL\n",
    "    edge_sobel = sobel(img)\n",
    "    edge_sobel1 = edge_sobel.reshape(-1)\n",
    "    df['Sobel'] = edge_sobel1\n",
    "\n",
    "    #SCHARR\n",
    "    edge_scharr = scharr(img)\n",
    "    edge_scharr1 = edge_scharr.reshape(-1)\n",
    "    df['Scharr'] = edge_scharr1\n",
    "\n",
    "    #PREWITT\n",
    "    edge_prewitt = prewitt(img)\n",
    "    edge_prewitt1 = edge_prewitt.reshape(-1)\n",
    "    df['Prewitt'] = edge_prewitt1\n",
    "\n",
    "    #GAUSSIAN with sigma=3\n",
    "    from scipy import ndimage as nd\n",
    "    gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "    gaussian_img1 = gaussian_img.reshape(-1)\n",
    "    df['Gaussian s3'] = gaussian_img1\n",
    "\n",
    "    #GAUSSIAN with sigma=7\n",
    "    gaussian_img2 = nd.gaussian_filter(img, sigma=7)\n",
    "    gaussian_img3 = gaussian_img2.reshape(-1)\n",
    "    df['Gaussian s7'] = gaussian_img3\n",
    "\n",
    "    #MEDIAN with sigma=3\n",
    "    median_img = nd.median_filter(img, size=3)\n",
    "    median_img1 = median_img.reshape(-1)\n",
    "    df['Median s3'] = median_img1\n",
    "\n",
    "#VARIANCE with size=3\n",
    "# slow part, we may not need that\n",
    "# variance_img = nd.generic_filter(img, np.var, size=3)\n",
    "# variance_img1 = variance_img.reshape(-1)\n",
    "# df['Variance s3'] = variance_img1  #Add column to original dataframe\n",
    "    \n",
    "    return df\n",
    "\n",
    "########\n",
    "# Everything from previous steps is useless because we are using\n",
    "# unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Import the pickled file\n",
    "filename = './2006251300008904.jpg'\n",
    "load_model = pickle.load(open(filename, 'rb')) #reading binary mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step through the folder containing images that need to be segmented\n",
    "\n",
    "#Go through each file - multiple files\n",
    "#Same as steps before except we use the for loop to step through files\n",
    "path = 'images/Train_images/*.jpg'\n",
    "for file in glob.glob(path):\n",
    "    img1 = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Do feature extraction and call the function which returns a df\n",
    "    X = feature_extraction(img)\n",
    "    result = load_model.predict(X) #the pickled model and predict\n",
    "    segmented = result.reshape((img.shape)) #reshape to my original img shape\n",
    "    name = file.split(\"e_\")\n",
    "    plt.imsave('images/Segmented/' + name[1], segmented, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image segmentation approach where we generated a bunch of features\n",
    "# from our input images and then trained a ML algo model (in this case RF)\n",
    "# saved the model and used it to segment a whole bunch of images\n",
    "# in a folder.\n",
    "\n",
    "#Leveraging the greatness of Gabor filter using texture to \n",
    "# perform segmentation\n",
    "\n",
    "# for limited amount of training images, traditional ML \n",
    "# beats DL. If you have more than 100 images for training, then \n",
    "# use DL and U-net approach.\n",
    "\n",
    "# Source: https://github.com/bnsreenu/python_for_microscopists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "\n",
    "#What are Gabor filters? \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(kernel)\n",
    "\n",
    "kernel_resized = cv2.resize(kernel, (400,400)) \n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Filtered Image', fimg)\n",
    "cv2.imshow('Kernel', kernel_resized)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#df.to_csv('Gabor.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 67 - Feature based image segmentation using traditional Machine Learning\n",
    "\n",
    "# Code adapted from: https://github.com/bnsreenu/python_for_microscopists/blob/master/067-ML_06_05_PREDICT_ML_segmentation_All_filters_RForest.py\n",
    "\n",
    "# Multi-training images \n",
    "# Good idea to label masks and images the same way \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying trained model to segment multiple files. \n",
    "\n",
    "filename = \"ourfirst_model\"\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "path = \"./images/Train_images/*.jpg\"\n",
    "for file in glob.glob(path):\n",
    "    print(file)     #just stop here to see all file names printed\n",
    "    img1= cv2.imread(file)\n",
    "    img1 = cv2.resize(img1, (128,128))\n",
    "    img = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Call the feature extraction function.\n",
    "    X = feature_extraction(img)\n",
    "    result = loaded_model.predict(X)\n",
    "    segmented = result.reshape((img.shape))\n",
    "    \n",
    "    name = file.split(\"e_\")\n",
    "    plt.imsave('images/Segmented/'+ name[1], segmented, cmap ='jet')\n",
    "\n",
    "#Above, we are splitting the file path into 2 -> creates a list with 2 entries\n",
    "#Then we are taking the second half of name to save segmented images with that name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#All features generated must match the way features are generated for TRAINING.\n",
    "#Feature1 is our original image pixels\n",
    "    img2 = img.reshape(-1)\n",
    "    df['Original Image'] = img2\n",
    "\n",
    "#Generate Gabor features\n",
    "    num = 1\n",
    "    kernels = []\n",
    "    for theta in range(2):\n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1, 3):\n",
    "            for lamda in np.arange(0, np.pi, np.pi / 4):\n",
    "                for gamma in (0.05, 0.5):\n",
    "#               print(theta, sigma, , lamda, frequency)\n",
    "                \n",
    "                    gabor_label = 'Gabor' + str(num)\n",
    "#                    print(gabor_label)\n",
    "                    ksize=9\n",
    "                    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)    \n",
    "                    kernels.append(kernel)\n",
    "                    #Now filter image and add values to new column\n",
    "                    fimg = cv2.filter2D(img2, cv2.CV_8UC3, kernel)\n",
    "                    filtered_img = fimg.reshape(-1)\n",
    "                    df[gabor_label] = filtered_img  #Modify this to add new column for each gabor\n",
    "                    num += 1\n",
    "                    \n",
    "########################################\n",
    "\n",
    "#Generate OTHER FEATURES and add them to the data frame\n",
    "#Feature 3 is canny edge\n",
    "    edges = cv2.Canny(img, 100,200)   #Image, min and max values\n",
    "    edges1 = edges.reshape(-1)\n",
    "    df['Canny Edge'] = edges1 #Add column to original dataframe\n",
    "\n",
    "    from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "\n",
    "#Feature 4 is Roberts edge\n",
    "    edge_roberts = roberts(img)\n",
    "    edge_roberts1 = edge_roberts.reshape(-1)\n",
    "    df['Roberts'] = edge_roberts1\n",
    "\n",
    "#Feature 5 is Sobel\n",
    "    edge_sobel = sobel(img)\n",
    "    edge_sobel1 = edge_sobel.reshape(-1)\n",
    "    df['Sobel'] = edge_sobel1\n",
    "\n",
    "#Feature 6 is Scharr\n",
    "    edge_scharr = scharr(img)\n",
    "    edge_scharr1 = edge_scharr.reshape(-1)\n",
    "    df['Scharr'] = edge_scharr1\n",
    "\n",
    "    #Feature 7 is Prewitt\n",
    "    edge_prewitt = prewitt(img)\n",
    "    edge_prewitt1 = edge_prewitt.reshape(-1)\n",
    "    df['Prewitt'] = edge_prewitt1\n",
    "\n",
    "    #Feature 8 is Gaussian with sigma=3\n",
    "    from scipy import ndimage as nd\n",
    "    gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "    gaussian_img1 = gaussian_img.reshape(-1)\n",
    "    df['Gaussian s3'] = gaussian_img1\n",
    "\n",
    "    #Feature 9 is Gaussian with sigma=7\n",
    "    gaussian_img2 = nd.gaussian_filter(img, sigma=7)\n",
    "    gaussian_img3 = gaussian_img2.reshape(-1)\n",
    "    df['Gaussian s7'] = gaussian_img3\n",
    "\n",
    "    #Feature 10 is Median with sigma=3\n",
    "    median_img = nd.median_filter(img, size=3)\n",
    "    median_img1 = median_img.reshape(-1)\n",
    "    df['Median s3'] = median_img1\n",
    "\n",
    "    #Feature 11 is Variance with size=3\n",
    "    variance_img = nd.generic_filter(img, np.var, size=3)\n",
    "    variance_img1 = variance_img.reshape(-1)\n",
    "    df['Variance s3'] = variance_img1  #Add column to original dataframe\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 26 - Denoising and edge detection using OpenCV \n",
    "\n",
    "# Code adapted from: https://github.com/bnsreenu/python_for_microscopists/blob/master/026-image_processing_in_openCV_intro1-preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising\n",
    "\n",
    "img = cv2.imread('./camera/2006251145008899.jpg')\n",
    "img = cv2.resize(img, (512,512))\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "filt_2D = cv2.filter2D(img,-1,kernel)    #Convolution using the kernel we provide\n",
    "blur = cv2.blur(img,(5,5))   #Convolution with a normalized filter. Same as above for this example.\n",
    "blur_gaussian = cv2.GaussianBlur(img,(5,5),0)  #Gaussian kernel is used. \n",
    "median_blur = median = cv2.medianBlur(img,5)  #Using kernel size 5. Better on edges compared to gaussian.\n",
    "bilateral_blur = cv2.bilateralFilter(img,9,75,75)  #Good for noise removal but retain edge sharpness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"2D filtered\", filt_2D)\n",
    "cv2.imshow(\"Blur\", blur)\n",
    "cv2.imshow(\"Gaussian Blur\", blur_gaussian)\n",
    "cv2.imshow(\"Median Blur\", median_blur)\n",
    "cv2.imshow(\"Bilateral\", bilateral_blur)\n",
    "cv2.waitKey(0)          \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge detection:\n",
    "    \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"./camera/2006251145008899.jpg\", 1)\n",
    "img = cv2.resize(img, (512,512))\n",
    "edges = cv2.Canny(img,100,200)   #Image, min and max values\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Canny\", edges)\n",
    "\n",
    "cv2.waitKey(0)          \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many ways to open images in Python.\n",
    "# PIL\n",
    "# matplotlib\n",
    "# skimage\n",
    "# openCV\n",
    "# other libraries to open propriatery images like czi, OME-TIFF\n",
    "\n",
    "# 1. Using PIL\n",
    "\n",
    "from PIL import Image \n",
    "import numpy as np   #Use numpy to convert images to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image \n",
    "img = Image.open(\"./camera/2006251145008899.jpg\") #Not a numpy array\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Images \n",
    "img.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints format of image \n",
    "print(img.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints mode of image \n",
    "print(img.mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIL is not by default numpy array but can convert PIL image to numpy array. \n",
    "img1 = np.asarray(img)\n",
    "print(type(img1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Using Matplotlib\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"./camera/2006251145008899.jpg\")  #this is a numpy array\n",
    "print(type(img))\n",
    "print(img)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.colorbar()   #Puts a color bar next to the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Using Scikit Image\n",
    "\n",
    "# Includes algorithms for segmentation, feature detection etc. \n",
    "# Great for Random forest or SVM\n",
    "from skimage import io, img_as_float, img_as_ubyte\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_as_float(io.imread(\"./2006251145008899.jpg\"))\n",
    "\n",
    "#image2 = io.imread(\"images/test_image.jpg\").astype(np.float)\n",
    "#avoid using astype as it violates assumptions about dtype range.\n",
    "#for example float should range from 0 to 1 (or -1 to 1) but if you use \n",
    "#astype to convert to float, the values do not lie between 0 and 1. \n",
    "print(image.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image8byte = img_as_ubyte(image)\n",
    "print(image8byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. using OpenCV\n",
    "\n",
    "# You can import images in color, grey scale or unchanged using \n",
    "# individual commands \n",
    "# cv2.IMREAD_COLOR : Loads a color image. Any transparency of image \n",
    "# will be neglected. It is the default flag.\n",
    "# cv2.IMREAD_GRAYSCALE : Loads image in grayscale mode\n",
    "# cv2.IMREAD_UNCHANGED : Loads image as such including alpha channel\n",
    "# Instead of these three flags, you can simply pass integers 1, 0 \n",
    "# or -1 respectively.\n",
    "\n",
    "import cv2\n",
    "\n",
    "grey_img = cv2.imread(\"./camera/2006251145008899.jpg\", 0)\n",
    "grey_img = cv2.resize(grey_img, (256,256))\n",
    "color_img = cv2.imread(\"./camera/2006251145008899.jpg\", 1)\n",
    "color_img = cv2.resize(color_img, (256,256))\n",
    "\n",
    "#images opened using cv2 are numpy arrays\n",
    "print(type(grey_img)) \n",
    "print(type(color_img)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function cv2.imshow() to display an image in a window. \n",
    "# First argument is the window name which is a string. second argument is our image. \n",
    "cv2.imshow(\"pic\", grey_img)\n",
    "cv2.imshow(\"color pic\", color_img)\n",
    "\n",
    "# Maintain output window until \n",
    "# user presses a key or 1000 ms (1s)\n",
    "cv2.waitKey(0)          \n",
    "\n",
    "#destroys all windows created\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV imread, imwrite and imshow all work with the BGR order, not RGB\n",
    "#but there is no need to change the order when you read an image with \n",
    "#cv2.imread and then want to show it with cv2.imshow\n",
    "#if you use matplotlib, it uses RGB. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(color_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #OpenCV represents RGB images as multi-dimensional NumPy arrays, but as BGR.\n",
    "\n",
    "#we can convert the images from BGR to RGB\n",
    "#plt.imshow(cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#We can also change color spaces from RGB to HSV..\n",
    "plt.imshow(cv2.cvtColor(color_img, cv2.COLOR_BGR2HSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Using Ome-tiff\n",
    "\n",
    "import apeer_ometiff_library\n",
    "from apeer_ometiff_library import io  #Use apeer.com free platform for image processing in the cloud\n",
    "\n",
    "#OME-TIFF has tiff and metada (as XML) embedded\n",
    "#Image is a 5D array.\n",
    "\n",
    "(pic2, omexml) = io.read_ometiff(\"./camera/2006251145008899.tif\")  #Unwrap image and embedded xml metadata\n",
    "print (pic2.shape)   #to verify the shape of the array\n",
    "print(pic2)\n",
    "\n",
    "print(omexml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CZI files \n",
    "\n",
    "import czifile\n",
    "\n",
    "img = czifile.imread('images/test_image.czi')\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "import czifile\n",
    "from skimage import io\n",
    "\n",
    "img = czifile.imread('images/Osteosarcoma_01.czi')\n",
    "print(img.shape)\n",
    "img1=img[0, 0, :, :, :, 0]\n",
    "print(img1.shape)\n",
    "img2=img1[2,:,:]\n",
    "io.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Reading multiple images from a folder\n",
    "\n",
    "# Glob module finds all the path names\n",
    "#matching a specified pattern according to the rules used by the Unix shell\n",
    "#The glob.glob returns the list of files with their full path \n",
    "\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the path\n",
    "\n",
    "# /*.jpg \n",
    "path = \"images/test_images/aeroplane/*.*\"\n",
    "for file in glob.glob(path):\n",
    "    print(file)     #just stop here to see all file names printed\n",
    "    a= cv2.imread(file)  #now, we can read each file since we have the full path\n",
    "    print(a)  #print numpy arrays for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at each file\n",
    "    cv2.imshow('Original Image', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each image - change color from BGR to RGB.\n",
    "    c = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('Color image', c)\n",
    "#wait for 1 second\n",
    "    k = cv2.waitKey(0)\n",
    "#destroy the window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 29 - Features, detectors, keypoints\n",
    "\n",
    "# Code adapted from: https://github.com/bnsreenu/python_for_microscopists/blob/master/029-keypoint%20detectors%20and%20descriptors%20in%20opencv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Harris corner \n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./camera/2006251145008899.jpg')\n",
    "img = cv2.resize(img, (256,256))\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)  #Harris works on float32 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input parameters\n",
    "# image, block size (size of neighborhood considered), ksize (aperture parameter for Sobel), k\n",
    "harris = cv2.cornerHarris(gray,2,3,0.04)  \n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[harris>0.01*harris.max()]=[255,0,0]    # replace these pixels with blue\n",
    "\n",
    "cv2.imshow('Harris Corners',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Shi-Tomasi Corner Detector & Good Features to Track\n",
    "# In opencv it is called goodfeaturestotrack\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./camera/2006251145008899.jpg')\n",
    "img = cv2.resize(img, (256,256))\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#input image, #points, quality level (0-1), min euclidean dist. between detected points\n",
    "corners = cv2.goodFeaturesToTrack(gray,50,0.05,10)\n",
    "corners = np.int0(corners)   #np.int0 is int64\n",
    "\n",
    "for i in corners:\n",
    "    x,y = i.ravel()   # Ravel Returns a contiguous flattened array.\n",
    "#    print(x,y)\n",
    "    cv2.circle(img,(x,y),3,255,-1)  #Draws circle (Img, center, radius, color, etc.)\n",
    "\n",
    "cv2.imshow('Corners',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FAST \n",
    "# Features from Accelerated Segment Test\n",
    "# High speed corner detector\n",
    "# FAST is only keypoint detector. Cannot get any descriptors. \n",
    "\n",
    "#SIFT and SURF - do not work in opencv 3\n",
    "#SIFT stands for scale invariant feature transform\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./camera/2006251145008899.jpg', 0)\n",
    "img = cv2.resize(img, (512,512))\n",
    "\n",
    "# Initiate FAST object with default values\n",
    "detector = cv2.FastFeatureDetector_create(50)   #Detects 50 points\n",
    "\n",
    "kp = detector.detect(img, None)\n",
    "\n",
    "img2 = cv2.drawKeypoints(img, kp, None, flags=0)\n",
    "\n",
    "plt.imshow(img2)\n",
    "cv2.imshow('Corners',img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ORB\n",
    "# Oriented FAST and Rotated BRIEF\n",
    "# An efficient alternative to SIFT or SURF\n",
    "# ORB is basically a fusion of FAST keypoint detector and BRIEF descriptor\n",
    "\n",
    "#BRIEF (Binary Robust Independent Elementary Features)\n",
    "#One important point is that BRIEF is a feature descriptor, \n",
    "#it doesn’t provide any method to find the features.\n",
    "# Not going to show the example as BRIEF also not working in opencv 3\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./camera/2006251145008899.jpg', 0)\n",
    "img = cv2.resize(img, (512,512))\n",
    "\n",
    "orb = cv2.ORB_create(100)\n",
    "kp, des = orb.detectAndCompute(img, None)\n",
    "\n",
    "# draw only keypoints location,not size and orientation\n",
    "#img2 = cv2.drawKeypoints(img, kp, None, flags=None)\n",
    "# Now, let us draw with rich key points, reflecting descriptors. \n",
    "# Descriptors here show both the scale and the orientation of the keypoint.\n",
    "img2 = cv2.drawKeypoints(img, kp, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow(\"With keypoints\", img2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
